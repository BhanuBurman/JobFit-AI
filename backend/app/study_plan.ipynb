{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37deec6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'Python vectordbenv (Python 3.12.3)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. /c:/Users/Bhanu/AppData/Roaming/Cursor/User/globalStorage/ms-toolsai.jupyter/version-2025.3.0/jupyter/runtime contains invalid WIN32 path characters."
     ]
    }
   ],
   "source": [
    "model=\"provider-3/gpt-4o-mini\"\n",
    "api_key=\"ddc-a4f-350c1c62c987412cabb6fd702c17fc9b\"\n",
    "base_url=\"https://api.a4f.co/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec13d69",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'Python vectordbenv (Python 3.12.3)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. /c:/Users/Bhanu/AppData/Roaming/Cursor/User/globalStorage/ms-toolsai.jupyter/version-2025.3.0/jupyter/runtime contains invalid WIN32 path characters."
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# LLM for extraction (structured output)\n",
    "extraction_llm = ChatOpenAI(\n",
    "    model=model,\n",
    "    api_key=api_key,\n",
    "    base_url=base_url,\n",
    "    temperature=0.1,  # Low temp for consistent extraction\n",
    ")\n",
    "\n",
    "# LLM for synthesis (more creative)\n",
    "synthesis_llm = ChatOpenAI(\n",
    "    model=model,\n",
    "    api_key=api_key,\n",
    "    base_url=base_url,\n",
    "    temperature=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b289a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi Bhanu! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 6, 'total_tokens': 17, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'provider-3/gpt-4o-mini', 'system_fingerprint': None, 'id': 'ddc-a4f-chatcmpl-78b146d5b2964da89b319f73b294f2f2', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--d4038d39-5827-4462-b526-4c568008055c-0', usage_metadata={'input_tokens': 6, 'output_tokens': 11, 'total_tokens': 17, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthesis_llm.invoke(\"Hi, This is Bhanu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb079740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job': {'title': 'Full Stack Engineer',\n",
       "  'company': 'Autopilot',\n",
       "  'full_description': '... expertise in React, Next.js, TypeScript, NestJS ...'},\n",
       " 'review': {'skills_score': 8,\n",
       "  'experience_score': 7,\n",
       "  'clarity_score': 6,\n",
       "  'missing_skills': ['Machine Learning', 'Cloud Computing'],\n",
       "  'strong_points': ['Docker', 'Kubernetes']},\n",
       " 'timeline_months': 3,\n",
       " 'experience_level': 'intermediate',\n",
       " 'rag_enabled': False,\n",
       " 'logs': []}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import TypedDict, List, Dict, Any, Optional\n",
    "# Define the state schema as per documentation\n",
    "class PlanState(TypedDict, total=False):\n",
    "    job: Dict[str, Any]  # job_match from API\n",
    "    review: Dict[str, Any]  # resume_analysis.review\n",
    "    \n",
    "    # Processing state\n",
    "    extracted_skills: List[str]\n",
    "    present_skills: List[str]\n",
    "    gaps: List[str]\n",
    "    priorities: Dict[str, List[str]]\n",
    "    \n",
    "    # Output state\n",
    "    basic_plan: List[Dict[str, Any]]\n",
    "    advanced_plan: List[Dict[str, Any]]\n",
    "    priority_analysis: Dict[str, Any]\n",
    "    score_improvements: Dict[str, int]\n",
    "    estimated_duration: str\n",
    "    \n",
    "    # Control flags\n",
    "    rag_enabled: bool\n",
    "    rationale: str\n",
    "    logs: List[str]\n",
    "    error: Optional[str]\n",
    "\n",
    "# Test state initialization\n",
    "initial_state = PlanState(\n",
    "    job={\"title\": \"Full Stack Engineer\", \"company\": \"Autopilot\", \n",
    "         \"full_description\": \"... expertise in React, Next.js, TypeScript, NestJS ...\"},\n",
    "    review={\"skills_score\": 8, \"experience_score\": 7, \"clarity_score\": 6, \n",
    "           \"missing_skills\": [\"Machine Learning\", \"Cloud Computing\"], \n",
    "           \"strong_points\": [\"Docker\", \"Kubernetes\"]},\n",
    "    timeline_months=3,\n",
    "    experience_level=\"intermediate\",\n",
    "    rag_enabled=False,\n",
    "    logs=[]\n",
    ")\n",
    "initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "603b8086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted skills: ['React', 'Next.js', 'TypeScript', 'NestJS']\n",
      "Logs: ['extract_skills: starting', \"extract_skills: rule-based found ['React', 'Next.js', 'TypeScript', 'NestJS']\"]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "def extract_skills(state: PlanState) -> PlanState:\n",
    "    \"\"\"Extract skills from job description - rule-first, LLM fallback\"\"\"\n",
    "    logs = state.get(\"logs\", []) + [\"extract_skills: starting\"]\n",
    "    \n",
    "    # Rule-based extraction first (deterministic)\n",
    "    jd_text = state[\"job\"][\"full_description\"].lower()\n",
    "    skill_patterns = {\n",
    "        \"React\": [\"react\", \"reactjs\", \"react.js\"],\n",
    "        \"Next.js\": [\"next.js\", \"nextjs\"],\n",
    "        \"TypeScript\": [\"typescript\", \"ts\"],\n",
    "        \"NestJS\": [\"nestjs\", \"nest.js\"],\n",
    "        \"Node.js\": [\"node.js\", \"nodejs\"],\n",
    "        \"Python\": [\"python\"],\n",
    "        \"Docker\": [\"docker\"],\n",
    "        \"Kubernetes\": [\"kubernetes\", \"k8s\"],\n",
    "        \"AWS\": [\"aws\"],\n",
    "        \"Azure\": [\"azure\"],\n",
    "        \"GCP\": [\"gcp\"],\n",
    "        \"Git\": [\"git\"],\n",
    "        \"GitHub\": [\"github\"],\n",
    "        \"GitLab\": [\"gitlab\"],\n",
    "        \"MYSQL\":[\"mysql\", \"sql\"],\n",
    "        \"PostgreSQL\":[\"postgresql\"],\n",
    "        \"MongoDB\":[\"mongodb\"]\n",
    "        \n",
    "    }\n",
    "    \n",
    "    extracted = []\n",
    "    for skill, patterns in skill_patterns.items():\n",
    "        if any(pattern in jd_text for pattern in patterns):\n",
    "            extracted.append(skill)\n",
    "    \n",
    "    # If rule-based found enough skills, use them\n",
    "    if len(extracted) >= 3:\n",
    "        logs.append(f\"extract_skills: rule-based found {extracted}\")\n",
    "        return {**state, \"extracted_skills\": extracted, \"logs\": logs}\n",
    "    \n",
    "    # LLM fallback for complex descriptions\n",
    "    try:\n",
    "        prompt = PromptTemplate.from_template(\"\"\"\n",
    "        Extract technical skills from this job description. Return only JSON with a \"skills\" array.\n",
    "        Focus on programming languages, frameworks, tools, and technologies.\n",
    "        \n",
    "        Job Description: {job_description}\n",
    "        \n",
    "        Return format: {{\"skills\": [\"skill1\", \"skill2\"]}}\n",
    "        \"\"\")\n",
    "        \n",
    "        chain = prompt | extraction_llm | JsonOutputParser()\n",
    "        result = chain.invoke({\"job_description\": state[\"job\"][\"full_description\"]})\n",
    "        \n",
    "        extracted = result.get(\"skills\", [])[:10]  # Limit to top 10\n",
    "        logs.append(f\"extract_skills: LLM fallback found {extracted}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logs.append(f\"extract_skills: LLM failed, using empty list: {str(e)}\")\n",
    "        extracted = []\n",
    "    \n",
    "    return {**state, \"extracted_skills\": extracted, \"logs\": logs}\n",
    "\n",
    "# Test the node\n",
    "test_result = extract_skills(initial_state)\n",
    "print(\"Extracted skills:\", test_result[\"extracted_skills\"])\n",
    "print(\"Logs:\", test_result[\"logs\"][-2:])  # Show last 2 logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c1f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_resume(state: PlanState) -> PlanState:\n",
    "    \"\"\"Ground resume capabilities from structured analysis - deterministic\"\"\"\n",
    "    logs = state.get(\"logs\", []) + [\"ground_resume: deriving present skills\"]\n",
    "    \n",
    "    review = state[\"review\"]\n",
    "    \n",
    "    # Present skills from strong_points and role_fit_analysis\n",
    "    present_skills = review.get(\"strong_points\", [])\n",
    "    \n",
    "    # Add skills mentioned in role_fit_analysis if available\n",
    "    role_fit = review.get(\"role_fit_analysis\", \"\")\n",
    "    if \"frontend\" in role_fit.lower() or \"react\" in role_fit.lower():\n",
    "        present_skills.extend([\"JavaScript\", \"HTML\", \"CSS\"])\n",
    "    if \"backend\" in role_fit.lower() or \"node\" in role_fit.lower():\n",
    "        present_skills.extend([\"JavaScript\", \"APIs\"])\n",
    "    \n",
    "    # Remove duplicates and normalize\n",
    "    present_skills = list(set(present_skills))\n",
    "    \n",
    "    # Experience level adjustment\n",
    "    exp_level = state.get(\"experience_level\", \"intermediate\")\n",
    "    if exp_level == \"beginner\":\n",
    "        # Add foundational skills\n",
    "        present_skills.extend([\"Programming Fundamentals\", \"Web Basics\"])\n",
    "    \n",
    "    logs.append(f\"ground_resume: present skills = {present_skills}\")\n",
    "    \n",
    "    return {**state, \"present_skills\": present_skills, \"logs\": logs}\n",
    "\n",
    "# Test the node\n",
    "test_state = ground_resume(initial_state)\n",
    "print(\"Present skills:\", test_state[\"present_skills\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python vectordbenv",
   "language": "python",
   "name": "vectorenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
